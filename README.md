# ü§ñ AI Agent Development Platform

> **Enterprise-grade platform for building, testing, and deploying AI agents with LangGraph**

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![LangGraph](https://img.shields.io/badge/LangGraph-Latest-green.svg)](https://langchain-ai.github.io/langgraph/)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

## üéØ Overview

This platform provides a comprehensive ecosystem for developing AI agents using LangGraph. It includes:

- **Core Agent Framework** - A robust foundation for building custom agents
- **Specialized Agents** - Pre-built agents for common tasks (code generation, testing, execution)
- **Docker Support** - Easy deployment with Docker Compose
- **Comprehensive Testing** - Built-in test suites and validation tools

## üöÄ Quick Start

### Prerequisites

- Python 3.8+
- Docker & Docker Compose (optional, for containerized deployment)
- Azure OpenAI API access (or OpenAI API)

### Installation

```bash
# Clone the repository
git clone <repository-url>
cd workspace

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
export AZURE_OPENAI_ENDPOINT="your-endpoint"
export OPENAI_API_KEY="your-api-key"
```

### Basic Usage

#### Option 1: Use Pre-built Agents

```python
# Complete Orchestration (Recommended)
from agent.orchestrator import OrchestratorAgent
orchestrator = OrchestratorAgent()
result = orchestrator.orchestrate(
    "Create a data processing module with tests",
    workflow_type="full_development"
)

# Or use individual agents:
# Code Generation
from agent.coder import CoderAgent
coder = CoderAgent()
result = coder.generate_agent(
    template_type="simple",
    agent_name="DataProcessor",
    purpose="Process CSV files and generate reports"
)

# Test Generation
from agent.tester import TesterAgent
tester = TesterAgent()
response = tester.chat("Generate tests for my authentication module")

# Code Execution
from agent.executor import ExecutorAgent
executor = ExecutorAgent()
response = executor.chat("Run pytest on my test suite")
```

#### Option 2: Build Custom Agents

```python
from core import CoreAgent, AgentConfig
from langchain_openai import ChatOpenAI

config = AgentConfig(
    name="MyCustomAgent",
    model=ChatOpenAI(model="gpt-4"),
    system_prompt="You are a specialized assistant for data analysis.",
    tools=[...],  # Add your tools
    enable_memory=True
)

agent = CoreAgent(config)
response = agent.invoke("Analyze this dataset...")
```

## üì¶ Project Structure

```
workspace/
‚îú‚îÄ‚îÄ core/                  # Core Agent Framework
‚îÇ   ‚îú‚îÄ‚îÄ agents.py         # CoreAgent implementation
‚îÇ   ‚îú‚îÄ‚îÄ config.py         # Configuration classes
‚îÇ   ‚îú‚îÄ‚îÄ managers/         # Feature managers (memory, rate limiting, etc.)
‚îÇ   ‚îî‚îÄ‚îÄ README.md         # Framework documentation
‚îú‚îÄ‚îÄ agent/                # Specialized Agents
‚îÇ   ‚îú‚îÄ‚îÄ coder/           # CoderAgent - generates agents
‚îÇ   ‚îú‚îÄ‚îÄ tester/          # TesterAgent - generates tests
‚îÇ   ‚îî‚îÄ‚îÄ executor/        # ExecutorAgent - executes code safely
‚îú‚îÄ‚îÄ tests/               # Test suites
‚îú‚îÄ‚îÄ docker-compose.yml   # Docker deployment
‚îî‚îÄ‚îÄ requirements.txt     # Python dependencies
```

## üéØ Specialized Agents

### üöÄ CoderAgent
**Purpose:** Generate, analyze, and optimize LangGraph agents

- 12 specialized tools for agent development
- Supports standalone and Core Agent modes
- Auto-generates tests and documentation
- [Full Documentation](agent/coder/README_coder.md)

### üß™ TesterAgent
**Purpose:** Generate comprehensive unit tests

- Creates pytest-compatible test suites
- Automatic fixture and mock generation
- Edge case identification
- Coverage analysis
- [Full Documentation](agent/tester/README_tester.md)

### ‚öôÔ∏è ExecutorAgent
**Purpose:** Safely execute code and run tests

- Sandboxed code execution
- Resource monitoring and limits
- Test execution with reports
- Error handling and recovery
- [Full Documentation](agent/executor/README_executor.md)

### üé≠ OrchestratorAgent
**Purpose:** Coordinate multiple agents in harmony

- 4 coordination patterns (Supervisor, Swarm, Pipeline, Adaptive)
- Orchestrates Coder, Tester, and Executor agents
- Workflow templates for common tasks
- Real-time progress monitoring
- [Full Documentation](agent/orchestrator/README_orchestrator.md)

## üê≥ Docker Deployment

### Quick Start with Docker

```bash
# Build and run all services
docker-compose up --build

# Or run specific services
docker-compose up redis postgres
```

### Services Included

- **Core Agent API** - REST API for agent interactions
- **Redis** - For memory and caching
- **PostgreSQL** - For persistent storage
- **Prometheus + Grafana** - Monitoring and metrics

## üõ†Ô∏è Configuration

### Environment Variables

```bash
# Azure OpenAI (recommended)
AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com/
OPENAI_API_KEY=your-api-key
OPENAI_API_VERSION=2023-12-01-preview

# Or standard OpenAI
OPENAI_API_KEY=your-openai-key

# Memory Backends (optional)
REDIS_URL=redis://localhost:6379
POSTGRES_URL=postgresql://user:pass@localhost/agentdb
MONGODB_URL=mongodb://localhost:27017/agents
```

### Agent Configuration

```python
from core import AgentConfig

config = AgentConfig(
    # Basic settings
    name="MyAgent",
    description="Agent purpose",
    
    # Model configuration
    model=ChatOpenAI(model="gpt-4", temperature=0.7),
    
    # Features
    enable_memory=True,
    memory_backend="redis",
    enable_rate_limiting=True,
    enable_streaming=True,
    
    # Tools
    tools=[...],
)
```

## üß™ Testing

```bash
# Run all tests
python -m pytest

# Run core framework tests
python -m pytest core/test_core/

# Run with coverage
python -m pytest --cov=core --cov=agent

# Run specific test
python core/test_core/test_core_agent_comprehensive.py
```

## üìö Documentation

- [Core Agent Framework Documentation](core/README.md)
- [CoderAgent Documentation](agent/coder/README_coder.md)
- [TesterAgent Documentation](agent/tester/README_tester.md)
- [ExecutorAgent Documentation](agent/executor/README_executor.md)
- [OrchestratorAgent Documentation](agent/orchestrator/README_orchestrator.md)
- [Configuration Guide](core/README.md#configuration-examples)
- [Multi-Agent Patterns](core/README.md#multi-agent-system-configuration)

## üöÄ Example: Complete Development Workflow

### Option 1: Manual Coordination
```python
from agent.coder import CoderAgent
from agent.tester import TesterAgent
from agent.executor import ExecutorAgent

# 1. Generate an agent
coder = CoderAgent()
result = coder.chat(
    "Create a web scraping agent that monitors product prices "
    "and sends alerts when prices drop"
)

# 2. Generate tests for it
tester = TesterAgent()
tests = tester.chat(f"Generate comprehensive tests for this code:\n{result}")

# 3. Execute the tests
executor = ExecutorAgent()
test_results = executor.chat(f"Run these tests:\n{tests}")

print("‚úÖ Agent created, tested, and validated!")
```

### Option 2: Automated Orchestration (Recommended)
```python
from agent.orchestrator import OrchestratorAgent

# Let the orchestrator handle everything
orchestrator = OrchestratorAgent()

result = orchestrator.orchestrate(
    "Create a web scraping agent that monitors product prices "
    "and sends alerts when prices drop",
    workflow_type="full_development"
)

print("‚úÖ Complete workflow executed automatically!")
print(result["report"])
```

## ü§ù Contributing

We welcome contributions! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- Built on [LangGraph](https://langchain-ai.github.io/langgraph/) by LangChain
- Powered by Azure OpenAI GPT-4
- Inspired by modern agent architectures

---

**Ready to build intelligent agents? Get started with the examples above!** üöÄ



**
**Single‚Äëagent flow**

1. **Receive the request**
   Turn the user‚Äôs request into a short **intent**.

2. **Is there a tool? (deterministic check)**

   * Look up whether there‚Äôs a suitable function in the Skill/Tool registry.
   * **If yes:** The LLM only fills in the arguments ‚Üí call the tool ‚Üí return the result.
   * **If no:** Switch to code‚Äëwriting mode.

3. **Write & run code (fallback)**

   * The agent generates the necessary code.
   * Execute it in a **sandbox** (with timeout, resource limits, network restrictions).

4. **Validate / test (if possible)**

   * Simple guardrails, schema checks, verify the file exists, size > 0, etc.

5. **Respond & log**

   * Return the result + output file/summary to the user.
   * Log metrics, cost, errors (optionally store to memory).

---

**Multi‚Äëagent**

1. **Supervisor / Router**
   Receives the user request, infers intent, and decides which agent to hand it to.

2. **Planner**
   Breaks the task into steps and decides which agent/tool will handle each step.

3. **Tool Executor**
   Safely invokes schema‚Äëdefined deterministic tools.

4. **Coder Agent**
   When there‚Äôs no ready tool / flexible scripting is needed, it writes code and runs it in a sandbox.

5. **Critic / Verifier (optional)**
   Tests outputs, catches errors and prompt‚Äëinjection attempts.

6. **Memory / KB (optional)**
   Stores past plans, tool call examples, user preferences.

> Depending on needs, you can add specialist agents like **Data Analyst, Researcher, Evaluator**, etc.


**MEMORY

What It Actually Means:
"Short-term Memory" = Conversation Memory
‚ùå It is not kept for a short time! (It can stay in Redis/Postgres for years)
‚úÖ Thread-based conversation history
‚úÖ Messages are automatically loaded
‚úÖ Separate for each thread_id

"Long-term Memory" = Knowledge Store
‚ùå It has nothing to do with how long it is stored
‚úÖ A key-value knowledge store
‚úÖ Manual save/load
‚úÖ Independent of threads

ü§∑ Why These Names?

LangGraph‚Äôs terminology: they just named it this way, and we follow it

Inspired by human memory psychology, but technically different

Usage Pattern:

Short-term = Active conversation (like working memory)

Long-term = Persistent knowledge (like permanent memory)

**


# Agent Platform ‚Äì Architecture Guide (Nested in `agents_functions/`)

## 1. Goal

This guide defines a **self‚Äëcontained agent platform** that lives inside a wider application repo under `agents_functions/`. It delivers two execution models‚Äî(1) a single LangGraph orchestrator Function and (2) a multi‚ÄëFunction Azure Service¬†Bus pipeline‚Äîwhile sharing the same agent code base. The document also explains how this sub‚Äëmodule integrates with the **parent project‚Äôs existing Docker¬†Compose and CI/CD**.

---

## 2. Top‚ÄëLevel Folder Layout

> Everything below resides **inside** the folder `agents_functions/` at the root of the parent repository.

```text
parent‚Äërepo
‚îÇ
‚îú‚îÄ ai/
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ core/                    # Common infrastructure code
‚îÇ   ‚îÇ   ‚îî‚îÄ core_agent.py        # Abstract BaseAgent + helpers
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ agents/                  # All concrete agents
‚îÇ   ‚îÇ   ‚îú‚îÄ scoper/scoper_agent.py
‚îÇ   ‚îÇ   ‚îú‚îÄ creator/creator_agent.py
‚îÇ   ‚îÇ   ‚îú‚îÄ publisher/publisher_agent.py
‚îÇ   ‚îÇ   ‚îî‚îÄ curator/curator_agent.py
‚îÇ   ‚îÇ   ‚îî‚îÄ */docs/README.md     # Per‚Äëagent docs
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ docs/                    # Global docs & ADRs for the agent platform
‚îÇ   ‚îÇ   ‚îú‚îÄ architecture.md
‚îÇ   ‚îÇ   ‚îî‚îÄ contributing.md
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ infra/                   # Bicep + azd
‚îÇ   ‚îÇ   ‚îú‚îÄ main.bicep  (RG, KV, Insights)
‚îÇ   ‚îÇ   ‚îú‚îÄ storage.bicep
‚îÇ   ‚îÇ   ‚îú‚îÄ servicebus.bicep
‚îÇ   ‚îÇ   ‚îî‚îÄ functionapps.bicep   # 5 Function Apps
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ solutions/
‚îÇ   ‚îÇ   ‚îú‚îÄ langgraph_orchestrator/   # Solution¬†A
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ orchestrator/agent_graph.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ orchestrator/handlers.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ orchestrator/function_app.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ host.json
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ requirements.txt
‚îÇ   ‚îÇ   ‚îî‚îÄ sb_functions/             # Solution¬†B
‚îÇ   ‚îÇ       ‚îú‚îÄ scoper_function/...
‚îÇ   ‚îÇ       ‚îú‚îÄ creator_function/...
‚îÇ   ‚îÇ       ‚îú‚îÄ publisher_function/...
‚îÇ   ‚îÇ       ‚îî‚îÄ curator_function/...
‚îÇ   ‚îÇ       ‚îú‚îÄ host.json
‚îÇ   ‚îÇ       ‚îî‚îÄ requirements.txt
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ demos/                  # End‚Äëto‚Äëend runnable examples per agent
‚îÇ   ‚îÇ   ‚îú‚îÄ scoper/
‚îÇ   ‚îÇ   ‚îú‚îÄ creator/
‚îÇ   ‚îÇ   ‚îú‚îÄ publisher/
‚îÇ   ‚îÇ   ‚îî‚îÄ curator/
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ scripts/
‚îÇ   ‚îÇ   ‚îú‚îÄ run_local.sh        # Start both solutions locally
‚îÇ   ‚îÇ   ‚îú‚îÄ deploy_local.sh     # `azd up` + slot swap (dev)
‚îÇ   ‚îÇ   ‚îî‚îÄ seed_test_data.py   # Push sample messages
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ tests/
‚îÇ   ‚îÇ   ‚îú‚îÄ unit/
‚îÇ   ‚îÇ   ‚îî‚îÄ contract/
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ .github/workflows/      # Scoped CI/CD for the sub‚Äëmodule
‚îÇ       ‚îú‚îÄ ci.yml
‚îÇ       ‚îî‚îÄ cd.yml
‚îÇ
‚îî‚îÄ docker‚Äëcompose.yml          # Parent‚Äëlevel compose, see ¬ß13
```

---

## 3. Shared Components

| Directory | Content                                       | Purpose                        |
| --------- | --------------------------------------------- | ------------------------------ |
| `core/`   | `core_agent.py`, `AgentContext`, OTEL helpers | **DRY, single point of truth** |
| `agents/` | Concrete agents that extend `CoreAgent`       | Imported by both solutions     |

---

## 4. Solution¬†A ‚Äì LangGraph Orchestrator

* **One** Python Azure Function App (HTTP trigger).
* `agent_graph.py` builds the LangGraph DAG and wires agents.
* Intended for fast POCs or local development with Docker¬†Compose (see ¬ß13).

### Runtime Flow

1. HTTP POST `/api/orchestrate` (user message).
2. LangGraph workflow ‚Üí `Scoper ‚Üí Creator ‚Üí Publisher ‚Üí Curator`.
3. Final response returned as HTTP¬†200.

---

## 5. Solution¬†B ‚Äì Service¬†Bus Pipeline

* Four Azure Function Apps (Scoper, Creator, Publisher, Curator) running independently.
* Message flow via **queues** except the last hop which uses a **topic + subscriptions** for audit fan‚Äëout.

| Queue/Topic                | Producer  | Consumer                                   | Reason         |
| -------------------------- | --------- | ------------------------------------------ | -------------- |
| `scoper-out`               | Scoper    | Creator                                    | point‚Äëto‚Äëpoint |
| `creator-out`              | Creator   | Publisher                                  | ‚Ä≥              |
| `publisher-events` (topic) | Publisher | Curator¬†(sub `main`) & Audit¬†(sub `audit`) | fan‚Äëout        |

---

## 6. Scripts

| Script              | Purpose          | Key Steps                                          |
| ------------------- | ---------------- | -------------------------------------------------- |
| `run_local.sh`      | Local dev runner | `func start` SB functions + `uvicorn` orchestrator |
| `deploy_local.sh`   | Dev‚Äëenv deploy   | `azd env new dev` ‚Üí `azd up`                       |
| `seed_test_data.py` | Demo data        | Sends test messages via Service¬†Bus SDK            |

---

## 7. CI / CD (Scoped)

### CI (`agents_functions/.github/workflows/ci.yml`)

```yaml
on:
  push:
    paths:
      - 'agents_functions/**'
```

* Matrix test for Python¬†3.11.
* Lint ‚Üí pytest ‚Üí upload zip artefacts.

### CD (`agents_functions/.github/workflows/cd.yml`)

```yaml
on:
  push:
    branches: [main]
    paths: ['agents_functions/**']
```

* `azure/login` + `azure/azd-action` ‚Üí `azd up` (prod).
* Both solutions deploy in parallel; slot swap ensures zero downtime.

> The parent project‚Äôs root workflow remains unchanged. It simply calls these child workflows if it needs holistic checks.

---

## 8. Local Development

* **Dev¬†Container** includes Python¬†3.11, Azure¬†CLI, Functions Core¬†Tools.
* `run_local.sh` spins up Azurite (if available) for local¬†SB/Blob emulation.
* Secrets stored in `.env` at `agents_functions/`.

---

## 9. Infrastructure (Bicep)

* All resources are prefixed with `agents‚Äëfx‚Äë<env>` to avoid collision with root app.
* `functionapps.bicep` provisions 5 Function Apps on Flex¬†Consumption.
* Key Vault + Managed Identities for secretless connectivity.

---

## 10. Security & Config

* Managed Identity ‚Üí Service¬†Bus¬†/ Storage with RBAC.
* Key Vault for LangChain or OpenAI keys.
* `host.json` fine‚Äëtunes `maxConcurrentCalls` + `prefetchCount`.

---

## 11. Observability

* OpenTelemetry instrumentation ‚Üí Azure Monitor.
* Alert on DLQs per subscription (`publisher-events/$DeadLetterQueue`).

---

## 12. Growth Path

1. Add agent folder under `agents/`, extend DAG or add new queue.
2. CI path filter auto‚Äëdetects and redeploys.
3. Promote to Premium plan if throughput demands.

---

## 13. Docker¬†Compose Integration (Parent¬†App)

The parent project already ships a `docker-compose.yml`. Extend it with an **orchestrator** service so local developers can run the LangGraph solution without Azure:

```yaml
aff-orchestrator:
  image: mcr.microsoft.com/azure-functions/python:4-python3.11
  volumes:
    - ./agents_functions/solutions/langgraph_orchestrator:/home/site/wwwroot
  environment:
    - AzureWebJobsScriptRoot=/home/site/wwwroot
    - FUNCTIONS_WORKER_RUNTIME=python
    - LANGCHAIN_API_KEY=${LANGCHAIN_API_KEY}
    - SERVICE_BUS_CONNECTION=Endpoint=sb://broker:5672/...
  ports:
    - "7072:80"
  depends_on:
    - broker   # e.g., a local RabbitMQ or none if using Azurite SB emulator
```

* **Why only the orchestrator?** Multi‚ÄëFunction pipeline requires Azure¬†Service¬†Bus triggers which are not available locally without heavy setup. For e2e tests you can still run `func start` via `run_local.sh`.
* Compose override files (`docker-compose.override.yml`) can tailor dev‚Äëcontainer envs.

The core application‚Äôs existing pipelines stay intact; they merely mount `agents_functions/` for code scanning or delegate to its dedicated workflows.

---

üéØ **Result:** A neatly encapsulated agent subsystem that plugs into an existing app‚Äôs Docker¬†Compose and CI/CD while staying fully autonomous for build & deploy.
