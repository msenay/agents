# ðŸ¤– AI Agent Development Platform

> **Enterprise-grade platform for building, testing, and deploying AI agents with LangGraph**

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![LangGraph](https://img.shields.io/badge/LangGraph-Latest-green.svg)](https://langchain-ai.github.io/langgraph/)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

## ðŸŽ¯ Overview

This platform provides a comprehensive ecosystem for developing AI agents using LangGraph. It includes:

- **Core Agent Framework** - A robust foundation for building custom agents
- **Specialized Agents** - Pre-built agents for common tasks (code generation, testing, execution)
- **Docker Support** - Easy deployment with Docker Compose
- **Comprehensive Testing** - Built-in test suites and validation tools

## ðŸš€ Quick Start

### Prerequisites

- Python 3.8+
- Docker & Docker Compose (optional, for containerized deployment)
- Azure OpenAI API access (or OpenAI API)

### Installation

```bash
# Clone the repository
git clone <repository-url>
cd workspace

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
export AZURE_OPENAI_ENDPOINT="your-endpoint"
export OPENAI_API_KEY="your-api-key"
```

### Basic Usage

#### Option 1: Use Pre-built Agents

```python
# Complete Orchestration (Recommended)
from agent.orchestrator import OrchestratorAgent
orchestrator = OrchestratorAgent()
result = orchestrator.orchestrate(
    "Create a data processing module with tests",
    workflow_type="full_development"
)

# Or use individual agents:
# Code Generation
from agent.coder import CoderAgent
coder = CoderAgent()
result = coder.generate_agent(
    template_type="simple",
    agent_name="DataProcessor",
    purpose="Process CSV files and generate reports"
)

# Test Generation
from agent.tester import TesterAgent
tester = TesterAgent()
response = tester.chat("Generate tests for my authentication module")

# Code Execution
from agent.executor import ExecutorAgent
executor = ExecutorAgent()
response = executor.chat("Run pytest on my test suite")
```

#### Option 2: Build Custom Agents

```python
from core import CoreAgent, AgentConfig
from langchain_openai import ChatOpenAI

config = AgentConfig(
    name="MyCustomAgent",
    model=ChatOpenAI(model="gpt-4"),
    system_prompt="You are a specialized assistant for data analysis.",
    tools=[...],  # Add your tools
    enable_memory=True
)

agent = CoreAgent(config)
response = agent.invoke("Analyze this dataset...")
```

## ðŸ“¦ Project Structure

```
workspace/
â”œâ”€â”€ core/                  # Core Agent Framework
â”‚   â”œâ”€â”€ agents.py         # CoreAgent implementation
â”‚   â”œâ”€â”€ config.py         # Configuration classes
â”‚   â”œâ”€â”€ managers/         # Feature managers (memory, rate limiting, etc.)
â”‚   â””â”€â”€ README.md         # Framework documentation
â”œâ”€â”€ agent/                # Specialized Agents
â”‚   â”œâ”€â”€ coder/           # CoderAgent - generates agents
â”‚   â”œâ”€â”€ tester/          # TesterAgent - generates tests
â”‚   â””â”€â”€ executor/        # ExecutorAgent - executes code safely
â”œâ”€â”€ tests/               # Test suites
â”œâ”€â”€ docker-compose.yml   # Docker deployment
â””â”€â”€ requirements.txt     # Python dependencies
```

## ðŸŽ¯ Specialized Agents

### ðŸš€ CoderAgent
**Purpose:** Generate, analyze, and optimize LangGraph agents

- 12 specialized tools for agent development
- Supports standalone and Core Agent modes
- Auto-generates tests and documentation
- [Full Documentation](agent/coder/README_coder.md)

### ðŸ§ª TesterAgent
**Purpose:** Generate comprehensive unit tests

- Creates pytest-compatible test suites
- Automatic fixture and mock generation
- Edge case identification
- Coverage analysis
- [Full Documentation](agent/tester/README_tester.md)

### âš™ï¸ ExecutorAgent
**Purpose:** Safely execute code and run tests

- Sandboxed code execution
- Resource monitoring and limits
- Test execution with reports
- Error handling and recovery
- [Full Documentation](agent/executor/README_executor.md)

### ðŸŽ­ OrchestratorAgent
**Purpose:** Coordinate multiple agents in harmony

- 4 coordination patterns (Supervisor, Swarm, Pipeline, Adaptive)
- Orchestrates Coder, Tester, and Executor agents
- Workflow templates for common tasks
- Real-time progress monitoring
- [Full Documentation](agent/orchestrator/README_orchestrator.md)

## ðŸ³ Docker Deployment

### Quick Start with Docker

```bash
# Build and run all services
docker-compose up --build

# Or run specific services
docker-compose up redis postgres
```

### Services Included

- **Core Agent API** - REST API for agent interactions
- **Redis** - For memory and caching
- **PostgreSQL** - For persistent storage
- **Prometheus + Grafana** - Monitoring and metrics

## ðŸ› ï¸ Configuration

### Environment Variables

```bash
# Azure OpenAI (recommended)
AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com/
OPENAI_API_KEY=your-api-key
OPENAI_API_VERSION=2023-12-01-preview

# Or standard OpenAI
OPENAI_API_KEY=your-openai-key

# Memory Backends (optional)
REDIS_URL=redis://localhost:6379
POSTGRES_URL=postgresql://user:pass@localhost/agentdb
MONGODB_URL=mongodb://localhost:27017/agents
```

### Agent Configuration

```python
from core import AgentConfig

config = AgentConfig(
    # Basic settings
    name="MyAgent",
    description="Agent purpose",
    
    # Model configuration
    model=ChatOpenAI(model="gpt-4", temperature=0.7),
    
    # Features
    enable_memory=True,
    memory_backend="redis",
    enable_rate_limiting=True,
    enable_streaming=True,
    
    # Tools
    tools=[...],
)
```

## ðŸ§ª Testing

```bash
# Run all tests
python -m pytest

# Run core framework tests
python -m pytest core/test_core/

# Run with coverage
python -m pytest --cov=core --cov=agent

# Run specific test
python core/test_core/test_core_agent_comprehensive.py
```

## ðŸ“š Documentation

- [Core Agent Framework Documentation](core/README.md)
- [CoderAgent Documentation](agent/coder/README_coder.md)
- [TesterAgent Documentation](agent/tester/README_tester.md)
- [ExecutorAgent Documentation](agent/executor/README_executor.md)
- [OrchestratorAgent Documentation](agent/orchestrator/README_orchestrator.md)
- [Configuration Guide](core/README.md#configuration-examples)
- [Multi-Agent Patterns](core/README.md#multi-agent-system-configuration)

## ðŸš€ Example: Complete Development Workflow

### Option 1: Manual Coordination
```python
from agent.coder import CoderAgent
from agent.tester import TesterAgent
from agent.executor import ExecutorAgent

# 1. Generate an agent
coder = CoderAgent()
result = coder.chat(
    "Create a web scraping agent that monitors product prices "
    "and sends alerts when prices drop"
)

# 2. Generate tests for it
tester = TesterAgent()
tests = tester.chat(f"Generate comprehensive tests for this code:\n{result}")

# 3. Execute the tests
executor = ExecutorAgent()
test_results = executor.chat(f"Run these tests:\n{tests}")

print("âœ… Agent created, tested, and validated!")
```

### Option 2: Automated Orchestration (Recommended)
```python
from agent.orchestrator import OrchestratorAgent

# Let the orchestrator handle everything
orchestrator = OrchestratorAgent()

result = orchestrator.orchestrate(
    "Create a web scraping agent that monitors product prices "
    "and sends alerts when prices drop",
    workflow_type="full_development"
)

print("âœ… Complete workflow executed automatically!")
print(result["report"])
```

## ðŸ¤ Contributing

We welcome contributions! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ðŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ðŸ™ Acknowledgments

- Built on [LangGraph](https://langchain-ai.github.io/langgraph/) by LangChain
- Powered by Azure OpenAI GPT-4
- Inspired by modern agent architectures

---

**Ready to build intelligent agents? Get started with the examples above!** ðŸš€



**
**Singleâ€‘agent flow**

1. **Receive the request**
   Turn the userâ€™s request into a short **intent**.

2. **Is there a tool? (deterministic check)**

   * Look up whether thereâ€™s a suitable function in the Skill/Tool registry.
   * **If yes:** The LLM only fills in the arguments â†’ call the tool â†’ return the result.
   * **If no:** Switch to codeâ€‘writing mode.

3. **Write & run code (fallback)**

   * The agent generates the necessary code.
   * Execute it in a **sandbox** (with timeout, resource limits, network restrictions).

4. **Validate / test (if possible)**

   * Simple guardrails, schema checks, verify the file exists, size > 0, etc.

5. **Respond & log**

   * Return the result + output file/summary to the user.
   * Log metrics, cost, errors (optionally store to memory).

---

**Multiâ€‘agent**

1. **Supervisor / Router**
   Receives the user request, infers intent, and decides which agent to hand it to.

2. **Planner**
   Breaks the task into steps and decides which agent/tool will handle each step.

3. **Tool Executor**
   Safely invokes schemaâ€‘defined deterministic tools.

4. **Coder Agent**
   When thereâ€™s no ready tool / flexible scripting is needed, it writes code and runs it in a sandbox.

5. **Critic / Verifier (optional)**
   Tests outputs, catches errors and promptâ€‘injection attempts.

6. **Memory / KB (optional)**
   Stores past plans, tool call examples, user preferences.

> Depending on needs, you can add specialist agents like **Data Analyst, Researcher, Evaluator**, etc.


**MEMORY

What It Actually Means:
"Short-term Memory" = Conversation Memory
âŒ It is not kept for a short time! (It can stay in Redis/Postgres for years)
âœ… Thread-based conversation history
âœ… Messages are automatically loaded
âœ… Separate for each thread_id

"Long-term Memory" = Knowledge Store
âŒ It has nothing to do with how long it is stored
âœ… A key-value knowledge store
âœ… Manual save/load
âœ… Independent of threads

ðŸ¤· Why These Names?

LangGraphâ€™s terminology: they just named it this way, and we follow it

Inspired by human memory psychology, but technically different

Usage Pattern:

Short-term = Active conversation (like working memory)

Long-term = Persistent knowledge (like permanent memory)

**


# Agent Platform â€“ Architecture Guide (Nested in `agents_functions/`)

## 1. Goal

This guide defines a **selfâ€‘contained agent platform** that lives inside a wider application repo under `agents_functions/`. It delivers two execution modelsâ€”(1) a single LangGraph orchestrator Function and (2) a multiâ€‘Function Azure ServiceÂ Bus pipelineâ€”while sharing the same agent code base. The document also explains how this subâ€‘module integrates with the **parent projectâ€™s existing DockerÂ Compose and CI/CD**.

---

## 2. Topâ€‘Level Folder Layout

> Everything below resides **inside** the folder `agents_functions/` at the root of the parent repository.

```text
parentâ€‘repo
â”‚
â”œâ”€ ai/
â”‚   â”‚
â”‚   â”œâ”€ core/                    # Common infrastructure code
â”‚   â”‚   â””â”€ core_agent.py        # Abstract BaseAgent + helpers
â”‚   â”‚
â”‚   â”œâ”€ agents/                  # All concrete agents
â”‚   â”‚   â”œâ”€ scoper/scoper_agent.py
â”‚   â”‚   â”œâ”€ creator/creator_agent.py
â”‚   â”‚   â”œâ”€ publisher/publisher_agent.py
â”‚   â”‚   â””â”€ curator/curator_agent.py
â”‚   â”‚   â””â”€ */docs/README.md     # Perâ€‘agent docs
â”‚   â”‚
â”‚   â”œâ”€ docs/                    # Global docs & ADRs for the agent platform
â”‚   â”‚   â”œâ”€ architecture.md
â”‚   â”‚   â””â”€ contributing.md
â”‚   â”‚
â”‚   â”œâ”€ infra/                   # Bicep + azd
â”‚   â”‚   â”œâ”€ main.bicep  (RG, KV, Insights)
â”‚   â”‚   â”œâ”€ storage.bicep
â”‚   â”‚   â”œâ”€ servicebus.bicep
â”‚   â”‚   â””â”€ functionapps.bicep   # 5 Function Apps
â”‚   â”‚
â”‚   â”œâ”€ solutions/
â”‚   â”‚   â”œâ”€ langgraph_orchestrator/   # SolutionÂ A
â”‚   â”‚   â”‚   â”œâ”€ orchestrator/agent_graph.py
â”‚   â”‚   â”‚   â”œâ”€ orchestrator/handlers.py
â”‚   â”‚   â”‚   â””â”€ orchestrator/function_app.py
â”‚   â”‚   â”‚   â”œâ”€ host.json
â”‚   â”‚   â”‚   â””â”€ requirements.txt
â”‚   â”‚   â””â”€ sb_functions/             # SolutionÂ B
â”‚   â”‚       â”œâ”€ scoper_function/...
â”‚   â”‚       â”œâ”€ creator_function/...
â”‚   â”‚       â”œâ”€ publisher_function/...
â”‚   â”‚       â””â”€ curator_function/...
â”‚   â”‚       â”œâ”€ host.json
â”‚   â”‚       â””â”€ requirements.txt
â”‚   â”‚
â”‚   â”œâ”€ demos/                  # Endâ€‘toâ€‘end runnable examples per agent
â”‚   â”‚   â”œâ”€ scoper/
â”‚   â”‚   â”œâ”€ creator/
â”‚   â”‚   â”œâ”€ publisher/
â”‚   â”‚   â””â”€ curator/
â”‚   â”‚
â”‚   â”œâ”€ scripts/
â”‚   â”‚   â”œâ”€ run_local.sh        # Start both solutions locally
â”‚   â”‚   â”œâ”€ deploy_local.sh     # `azd up` + slot swap (dev)
â”‚   â”‚   â””â”€ seed_test_data.py   # Push sample messages
â”‚   â”‚
â”‚   â”œâ”€ tests/
â”‚   â”‚   â”œâ”€ unit/
â”‚   â”‚   â””â”€ contract/
â”‚   â”‚
â”‚   â””â”€ .github/workflows/      # Scoped CI/CD for the subâ€‘module
â”‚       â”œâ”€ ci.yml
â”‚       â””â”€ cd.yml
â”‚
â””â”€ dockerâ€‘compose.yml          # Parentâ€‘level compose, see Â§13
```

---

## 3. Shared Components

| Directory | Content                                       | Purpose                        |
| --------- | --------------------------------------------- | ------------------------------ |
| `core/`   | `core_agent.py`, `AgentContext`, OTEL helpers | **DRY, single point of truth** |
| `agents/` | Concrete agents that extend `CoreAgent`       | Imported by both solutions     |

---

## 4. SolutionÂ A â€“ LangGraph Orchestrator

* **One** Python Azure Function App (HTTP trigger).
* `agent_graph.py` builds the LangGraph DAG and wires agents.
* Intended for fast POCs or local development with DockerÂ Compose (see Â§13).

### Runtime Flow

1. HTTP POST `/api/orchestrate` (user message).
2. LangGraph workflow â†’ `Scoper â†’ Creator â†’ Publisher â†’ Curator`.
3. Final response returned as HTTPÂ 200.

---

## 5. SolutionÂ B â€“ ServiceÂ Bus Pipeline

* Four Azure Function Apps (Scoper, Creator, Publisher, Curator) running independently.
* Message flow via **queues** except the last hop which uses a **topic + subscriptions** for audit fanâ€‘out.

| Queue/Topic                | Producer  | Consumer                                   | Reason         |
| -------------------------- | --------- | ------------------------------------------ | -------------- |
| `scoper-out`               | Scoper    | Creator                                    | pointâ€‘toâ€‘point |
| `creator-out`              | Creator   | Publisher                                  | â€³              |
| `publisher-events` (topic) | Publisher | CuratorÂ (sub `main`) & AuditÂ (sub `audit`) | fanâ€‘out        |

---

## 6. Scripts

| Script              | Purpose          | Key Steps                                          |
| ------------------- | ---------------- | -------------------------------------------------- |
| `run_local.sh`      | Local dev runner | `func start` SB functions + `uvicorn` orchestrator |
| `deploy_local.sh`   | Devâ€‘env deploy   | `azd env new dev` â†’ `azd up`                       |
| `seed_test_data.py` | Demo data        | Sends test messages via ServiceÂ Bus SDK            |

---

## 7. CI / CD (Scoped)

### CI (`agents_functions/.github/workflows/ci.yml`)

```yaml
on:
  push:
    paths:
      - 'agents_functions/**'
```

* Matrix test for PythonÂ 3.11.
* Lint â†’ pytest â†’ upload zip artefacts.

### CD (`agents_functions/.github/workflows/cd.yml`)

```yaml
on:
  push:
    branches: [main]
    paths: ['agents_functions/**']
```

* `azure/login` + `azure/azd-action` â†’ `azd up` (prod).
* Both solutions deploy in parallel; slot swap ensures zero downtime.

> The parent projectâ€™s root workflow remains unchanged. It simply calls these child workflows if it needs holistic checks.

---

## 8. Local Development

* **DevÂ Container** includes PythonÂ 3.11, AzureÂ CLI, Functions CoreÂ Tools.
* `run_local.sh` spins up Azurite (if available) for localÂ SB/Blob emulation.
* Secrets stored in `.env` at `agents_functions/`.

---

## 9. Infrastructure (Bicep)

* All resources are prefixed with `agentsâ€‘fxâ€‘<env>` to avoid collision with root app.
* `functionapps.bicep` provisions 5 Function Apps on FlexÂ Consumption.
* Key Vault + Managed Identities for secretless connectivity.

---

## 10. Security & Config

* Managed Identity â†’ ServiceÂ BusÂ / Storage with RBAC.
* Key Vault for LangChain or OpenAI keys.
* `host.json` fineâ€‘tunes `maxConcurrentCalls` + `prefetchCount`.

---

## 11. Observability

* OpenTelemetry instrumentation â†’ Azure Monitor.
* Alert on DLQs per subscription (`publisher-events/$DeadLetterQueue`).

---

## 12. Growth Path

1. Add agent folder under `agents/`, extend DAG or add new queue.
2. CI path filter autoâ€‘detects and redeploys.
3. Promote to Premium plan if throughput demands.

---

## 13. DockerÂ Compose Integration (ParentÂ App)

The parent project already ships a `docker-compose.yml`. Extend it with an **orchestrator** service so local developers can run the LangGraph solution without Azure:

```yaml
aff-orchestrator:
  image: mcr.microsoft.com/azure-functions/python:4-python3.11
  volumes:
    - ./agents_functions/solutions/langgraph_orchestrator:/home/site/wwwroot
  environment:
    - AzureWebJobsScriptRoot=/home/site/wwwroot
    - FUNCTIONS_WORKER_RUNTIME=python
    - LANGCHAIN_API_KEY=${LANGCHAIN_API_KEY}
    - SERVICE_BUS_CONNECTION=Endpoint=sb://broker:5672/...
  ports:
    - "7072:80"
  depends_on:
    - broker   # e.g., a local RabbitMQ or none if using Azurite SB emulator
```

* **Why only the orchestrator?** Multiâ€‘Function pipeline requires AzureÂ ServiceÂ Bus triggers which are not available locally without heavy setup. For e2e tests you can still run `func start` via `run_local.sh`.
* Compose override files (`docker-compose.override.yml`) can tailor devâ€‘container envs.

The core applicationâ€™s existing pipelines stay intact; they merely mount `agents_functions/` for code scanning or delegate to its dedicated workflows.

---

ðŸŽ¯ **Result:** A neatly encapsulated agent subsystem that plugs into an existing appâ€™s DockerÂ Compose and CI/CD while staying fully autonomous for build & deploy.
