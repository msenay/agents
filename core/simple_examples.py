#!/usr/bin/env python3
"""
Core Agent - Basit KullanÄ±m Ã–rnekleri
Direkt Ã§alÄ±ÅŸtÄ±rÄ±labilir Ã¶rnekler
"""

from core import CoreAgent, AgentConfig
from langchain_core.language_models import BaseChatModel
from langchain_core.messages import AIMessage, BaseMessage
from langchain_core.tools import tool
from typing import List, Any


# Mock model for testing (gerÃ§ek kullanÄ±mda ChatOpenAI kullan)
class MockLLM(BaseChatModel):
    def _generate(self, messages: List[BaseMessage], **kwargs) -> Any:
        user_msg = messages[-1].content if messages else ""
        return AIMessage(content=f"Merhaba! MesajÄ±nÄ± aldÄ±m: '{user_msg}'")
    
    @property
    def _llm_type(self) -> str:
        return "mock"
    
    def invoke(self, input: Any, config=None, **kwargs) -> BaseMessage:
        if isinstance(input, list):
            return self._generate(input)
        return AIMessage(content=f"YanÄ±t: {input}")


# ============================================================
# Ã–RNEK 1: En Basit Agent
# ============================================================
def example_1_minimal_agent():
    """En minimal agent Ã¶rneÄŸi"""
    print("=" * 50)
    print("Ã–RNEK 1: Minimal Agent")
    print("=" * 50)
    
    # Config - sadece zorunlu parametreler
    config = AgentConfig(
        name="MinimalAgent",
        model=MockLLM()
    )
    
    # Agent oluÅŸtur
    agent = CoreAgent(config)
    
    # Kullan
    response = agent.invoke("Merhaba dÃ¼nya!")
    print(f"YanÄ±t: {response['messages'][-1].content}")


# ============================================================
# Ã–RNEK 2: System Prompt'lu Agent
# ============================================================
def example_2_with_prompt():
    """System prompt'lu agent"""
    print("\n" + "=" * 50)
    print("Ã–RNEK 2: System Prompt'lu Agent")
    print("=" * 50)
    
    config = AgentConfig(
        name="AsistanAgent",
        model=MockLLM(),
        system_prompt="Sen yardÄ±msever bir asistansÄ±n. Her zaman nazik ve profesyonel ol."
    )
    
    agent = CoreAgent(config)
    response = agent.invoke("BugÃ¼n hava nasÄ±l?")
    print(f"YanÄ±t: {response['messages'][-1].content}")


# ============================================================
# Ã–RNEK 3: Tool'lu Agent
# ============================================================
def example_3_with_tools():
    """Tool kullanan agent"""
    print("\n" + "=" * 50)
    print("Ã–RNEK 3: Tool'lu Agent")
    print("=" * 50)
    
    # Basit bir tool tanÄ±mla
    @tool
    def hesap_makinesi(islem: str) -> str:
        """Basit matematik iÅŸlemleri yapar. Ã–rnek: '2 + 2' veya '10 * 5'"""
        try:
            sonuc = eval(islem)
            return f"SonuÃ§: {sonuc}"
        except:
            return "Hata: GeÃ§ersiz iÅŸlem"
    
    @tool
    def tarih_saat() -> str:
        """Åu anki tarih ve saati dÃ¶ndÃ¼rÃ¼r"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    # Config
    config = AgentConfig(
        name="ToolAgent",
        model=MockLLM(),
        system_prompt="Sen matematik ve zaman konularÄ±nda yardÄ±mcÄ± olan bir asistansÄ±n.",
        tools=[hesap_makinesi, tarih_saat]
    )
    
    agent = CoreAgent(config)
    print(f"KullanÄ±labilir tool'lar: {[t.name for t in config.tools]}")


# ============================================================
# Ã–RNEK 4: Memory'li Agent
# ============================================================
def example_4_with_memory():
    """Memory kullanan agent"""
    print("\n" + "=" * 50)
    print("Ã–RNEK 4: Memory'li Agent")
    print("=" * 50)
    
    config = AgentConfig(
        name="MemoryAgent",
        model=MockLLM(),
        system_prompt="Sen hafÄ±zasÄ± olan bir asistansÄ±n.",
        
        # Memory ayarlarÄ±
        enable_memory=True,
        memory_backend="inmemory",
        memory_types=["short_term"]  # Thread-based conversation memory
    )
    
    agent = CoreAgent(config)
    
    # Thread 1'de konuÅŸma
    print("\nThread 1:")
    agent.invoke("Benim adÄ±m Ahmet", config={"configurable": {"thread_id": "user_1"}})
    agent.invoke("AdÄ±mÄ± hatÄ±rlÄ±yor musun?", config={"configurable": {"thread_id": "user_1"}})
    
    # Thread 2'de farklÄ± konuÅŸma
    print("\nThread 2:")
    agent.invoke("Ben Mehmet", config={"configurable": {"thread_id": "user_2"}})
    agent.invoke("Kim olduÄŸumu biliyor musun?", config={"configurable": {"thread_id": "user_2"}})


# ============================================================
# Ã–RNEK 5: Streaming Agent
# ============================================================
def example_5_streaming():
    """Streaming destekli agent"""
    print("\n" + "=" * 50)
    print("Ã–RNEK 5: Streaming Agent")
    print("=" * 50)
    
    config = AgentConfig(
        name="StreamingAgent",
        model=MockLLM(),
        enable_streaming=True
    )
    
    agent = CoreAgent(config)
    
    # Stream kullanÄ±mÄ±
    print("Streaming yanÄ±t:")
    for chunk in agent.stream("Uzun bir hikaye anlat"):
        # GerÃ§ek kullanÄ±mda chunk'lar parÃ§a parÃ§a gelir
        print(".", end="", flush=True)
    print("\nStreaming tamamlandÄ±!")


# ============================================================
# Ã–RNEK 6: Rate Limited Agent
# ============================================================
def example_6_rate_limited():
    """Rate limiting'li agent"""
    print("\n" + "=" * 50)
    print("Ã–RNEK 6: Rate Limited Agent")
    print("=" * 50)
    
    config = AgentConfig(
        name="RateLimitedAgent",
        model=MockLLM(),
        
        # Rate limiting
        enable_rate_limiting=True,
        requests_per_second=2.0,  # Saniyede max 2 istek
        max_bucket_size=5.0
    )
    
    agent = CoreAgent(config)
    print(f"Rate limit: {config.requests_per_second} istek/saniye")


# ============================================================
# FACTORY PATTERN Ã–RNEÄÄ°
# ============================================================
class AgentFactory:
    """Agent oluÅŸturmak iÃ§in factory pattern"""
    
    @staticmethod
    def create_chatbot(name: str = "Chatbot") -> CoreAgent:
        """Basit bir chatbot oluÅŸtur"""
        return CoreAgent(AgentConfig(
            name=name,
            model=MockLLM(),
            system_prompt="Sen samimi ve yardÄ±msever bir chatbotsun.",
            enable_memory=True,
            memory_backend="inmemory"
        ))
    
    @staticmethod
    def create_coder(name: str = "Coder") -> CoreAgent:
        """Kod yazan agent oluÅŸtur"""
        
        @tool
        def python_runner(code: str) -> str:
            """Python kodunu Ã§alÄ±ÅŸtÄ±rÄ±r"""
            return "Kod Ã§alÄ±ÅŸtÄ±rÄ±ldÄ± (simÃ¼lasyon)"
        
        return CoreAgent(AgentConfig(
            name=name,
            model=MockLLM(),
            system_prompt="Sen uzman bir Python geliÅŸtiricisisin.",
            tools=[python_runner],
            enable_memory=True
        ))
    
    @staticmethod
    def create_researcher(name: str = "Researcher") -> CoreAgent:
        """AraÅŸtÄ±rma yapan agent oluÅŸtur"""
        
        @tool
        def web_search(query: str) -> str:
            """Web'de arama yapar"""
            return f"'{query}' iÃ§in arama sonuÃ§larÄ± (simÃ¼lasyon)"
        
        return CoreAgent(AgentConfig(
            name=name,
            model=MockLLM(),
            system_prompt="Sen detaylÄ± araÅŸtÄ±rma yapan bir asistansÄ±n.",
            tools=[web_search],
            enable_memory=True,
            memory_types=["short_term", "long_term"]
        ))


# ============================================================
# Ã‡ALIÅTIR
# ============================================================
if __name__ == "__main__":
    print("ğŸš€ Core Agent Basit Ã–rnekler\n")
    
    # TÃ¼m Ã¶rnekleri Ã§alÄ±ÅŸtÄ±r
    example_1_minimal_agent()
    example_2_with_prompt()
    example_3_with_tools()
    example_4_with_memory()
    example_5_streaming()
    example_6_rate_limited()
    
    # Factory pattern Ã¶rneÄŸi
    print("\n" + "=" * 50)
    print("FACTORY PATTERN Ã–RNEÄÄ°")
    print("=" * 50)
    
    factory = AgentFactory()
    
    # HazÄ±r agent'lar oluÅŸtur
    chatbot = factory.create_chatbot("SohbetBotu")
    coder = factory.create_coder("KodYazÄ±cÄ±")
    researcher = factory.create_researcher("AraÅŸtÄ±rmacÄ±")
    
    print(f"âœ… {chatbot.config.name} oluÅŸturuldu")
    print(f"âœ… {coder.config.name} oluÅŸturuldu")
    print(f"âœ… {researcher.config.name} oluÅŸturuldu")
    
    print("\nâœ¨ TÃ¼m Ã¶rnekler tamamlandÄ±!")
    print("\nğŸ“Œ GerÃ§ek kullanÄ±m iÃ§in:")
    print("   - MockLLM yerine ChatOpenAI kullan")
    print("   - GerÃ§ek tool'lar ekle")
    print("   - Production iÃ§in Redis/PostgreSQL backend kullan")